{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EmmYDRwIEl4j"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "from pyspark.mllib.feature import HashingTF, IDF\n",
        "from pyspark.ml import Pipeline\n",
        "import os\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQwHaMOVEl4o"
      },
      "source": [
        "# Import necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iMG-6B6El4r",
        "outputId": "2d00da87-94cb-4a31-ae1b-4bb011091e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- avg_rating: string (nullable = true)\n",
            " |-- num_review: string (nullable = true)\n",
            " |-- num_sold: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            " |-- product_name: string (nullable = true)\n",
            " |-- brand: string (nullable = true)\n",
            " |-- origin: string (nullable = true)\n",
            " |-- first_category: string (nullable = true)\n",
            " |-- second_category: string (nullable = true)\n",
            " |-- third_category: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- shop_name: string (nullable = true)\n",
            " |-- shop_like_tier: string (nullable = true)\n",
            " |-- shop_num_review: string (nullable = true)\n",
            " |-- shop_reply_percentage: string (nullable = true)\n",
            " |-- shop_reply_time: string (nullable = true)\n",
            " |-- shop_creation_time: string (nullable = true)\n",
            " |-- shop_num_follower: string (nullable = true)\n",
            " |-- name_description: string (nullable = true)\n",
            " |-- augmented_description: string (nullable = true)\n",
            "\n",
            "+----------+----------+--------+------+--------------------+-----+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------+---------------+---------------------+---------------+------------------+-----------------+--------------------+---------------------+\n",
            "|avg_rating|num_review|num_sold| price|        product_name|brand|              origin|   first_category|     second_category|      third_category|         description|           shop_name|shop_like_tier|shop_num_review|shop_reply_percentage|shop_reply_time|shop_creation_time|shop_num_follower|    name_description|augmented_description|\n",
            "+----------+----------+--------+------+--------------------+-----+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------+---------------+---------------------+---------------+------------------+-----------------+--------------------+---------------------+\n",
            "|       4.8|    1100.0|  6300.0| 38900|0 12 tuổi 5 cặp v...| null|          nước ngoài|thời trang trẻ em|thời trang trẻ em...|thời trang trẻ em...|0 12 tuổi  bộ 5 c...|       mossovy011.vn|             0|        21800.0|                 0.22|  trong vài giờ|              28.0|          20900.0|0 12 tuổi 5 cặp v...| 0 12 tuổi 5 cặp v...|\n",
            "|       5.0|      20.0|    98.0|138750|0 4 tuổi link 1 t...| null|              hà nội|thời trang trẻ em|thời trang trẻ em...|                  no|note  gõ tìm kiếm...|   mon_designforkids|             1|        12300.0|                 0.86|  trong vài giờ|              30.0|          43100.0|0 4 tuổi link 1 t...| 0 4 tuổi link 1 t...|\n",
            "|       4.9|     268.0|  3900.0| 19000|0 5 tuổi tất vớ c...| null|              hà nội|thời trang trẻ em|thời trang trẻ em...|thời trang trẻ em...|mẹ ơi siêu phẩm t...|        nanashop2502|             1|         5200.0|                 0.88|  trong vài giờ|              48.0|          16500.0|0 5 tuổi tất vớ c...| 0 5 tuổi tất vớ c...|\n",
            "|       3.8|       4.0|    17.0| 90000|013 romance thời ...| null|          nước ngoài|   thời trang nam|thời trang nam / ...|thời trang nam / ...|xuất xứ  cn  xuất...|       chutoutian.vn|             0|            5.0|                 0.88|  trong vài giờ|               5.0|             18.0|013 romance thời ...| 013 romance thời ...|\n",
            "|       4.9|      38.0|   172.0| 18000|1 bộ khuyên tai n...| null|          nước ngoài|   thời trang nam|thời trang nam / ...|thời trang nam / ...|chào mừng bạn đến...|fashionofficialje...|             1|         1700.0|                 0.69|  trong vài giờ|               9.0|           2200.0|1 bộ khuyên tai n...| 1 bộ khuyên tai n...|\n",
            "|       5.0|       8.0|    39.0| 25000|1 chiếc khuyên dâ...| null|     tp. hồ chí minh|   thời trang nam|thời trang nam / ...|thời trang nam / ...|kích thước   như mẫu|      shoptrangsuchh|             2|        13600.0|                 0.99|  trong vài giờ|              27.0|           5000.0|1 chiếc khuyên dâ...| 1 chiếc khuyên dâ...|\n",
            "|       5.0|       2.0|    39.0|  1000|1 chiếc khẩu tran...| null|              hà nội|thời trang trẻ em|thời trang trẻ em...|                  no|giới thiệu shop a...|  bui_hien.hiuhiu156|             1|         8200.0|                 0.99|  trong vài giờ|              72.0|          31800.0|1 chiếc khẩu tran...| 1 chiếc khẩu tran...|\n",
            "|       4.6|      21.0|    89.0| 18000|1 chiếc lẻ size k...| null|huyện thường tín,...|    thời trang nữ| thời trang nữ / vải|thời trang nữ / v...|1 cây kim móc mô ...|    shoplenngocnhien|             2|        21000.0|                 0.92|  trong vài giờ|              84.0|          10200.0|1 chiếc lẻ size k...| 1 chiếc lẻ size k...|\n",
            "|       4.9|    2200.0| 20100.0| 13000|1 chiếc sịp chéo ...| null|              hà nội|   thời trang nam|thời trang nam / ...|thời trang nam / ...|với các lỗ thông ...|         thuthuy9889|             2|       268100.0|                  1.0|  trong vài giờ|              84.0|         196700.0|1 chiếc sịp chéo ...| 1 chiếc sịp chéo ...|\n",
            "|       4.9|      78.0|   323.0| 55540|1 cặp đai giữ áo ...| null|          nước ngoài|   thời trang nam|thời trang nam / ...|thời trang nam / ...|thời gian giao hà...|      instylelady.vn|             0|         2200.0|                 0.66|  trong vài giờ|              48.0|           1700.0|1 cặp đai giữ áo ...| 1 cặp đai giữ áo ...|\n",
            "|       5.0|      19.0|    53.0|  8000|1 hộp bông tăm ch...| null|              hà nội|thời trang trẻ em|thời trang trẻ em...|                  no|tăm bông là sản p...|   dososinhgiare1234|             1|         4500.0|                 0.76|  trong vài giờ|              36.0|           1300.0|1 hộp bông tăm ch...| 1 hộp bông tăm ch...|\n",
            "|       4.8|      17.0|   126.0|  8299|1 khuyên kẹp vành...| null|          nước ngoài|   thời trang nam|thời trang nam / ...|thời trang nam / ...|chào mừng đến với...|   marvelousworld.vn|             1|       252600.0|                 0.98| trong vài phút|              60.0|         163600.0|1 khuyên kẹp vành...| 1 khuyên kẹp vành...|\n",
            "|       4.8|     453.0|  5200.0|  4480|1 kẹp tóc hình tr...| null|          nước ngoài|thời trang trẻ em|thời trang trẻ em...|thời trang trẻ em...|                null|          kidbows.vn|             1|         4200.0|                 0.75|  trong vài giờ|               8.0|           7600.0|1 kẹp tóc hình tr...| 1 kẹp tóc hình tr...|\n",
            "|       4.9|    1300.0| 14100.0|  5000|1 nhẫn nhẫn công ...| null|          nước ngoài|thời trang trẻ em|thời trang trẻ em...|thời trang trẻ em...|xin chú ý đó là g...|         evanfang.vn|             1|         6200.0|                  0.7|  trong vài giờ|              20.0|           6800.0|1 nhẫn nhẫn công ...| 1 nhẫn nhẫn công ...|\n",
            "|       4.9|     330.0|   814.0|150000|1 áo khoác dáng d...| null|quận bắc từ liêm,...|thời trang trẻ em|thời trang trẻ em...|                  no|áo khoác dáng dài...|        moonchipshop|             0|        13500.0|                 0.59|  trong vài giờ|              72.0|          41600.0|1 áo khoác dáng d...| 1 áo khoác dáng d...|\n",
            "|       4.8|      93.0|   515.0| 35000|1 đôi bông tai na...| null|     tp. hồ chí minh|   thời trang nam|thời trang nam / ...|thời trang nam / ...|chất liệu  hợp ki...|nanastorephukienxinh|             0|          177.0|                 0.85|  trong vài giờ|              48.0|            101.0|1 đôi bông tai na...| 1 đôi bông tai na...|\n",
            "|       4.9|     461.0|  5900.0| 10000|1 đôi dép hài đi ...| null|              hà nội|thời trang trẻ em|thời trang trẻ em...|thời trang trẻ em...|trời lạnh quá các...|         thuthuy9889|             2|       268100.0|                  1.0|  trong vài giờ|              84.0|         196600.0|1 đôi dép hài đi ...| 1 đôi dép hài đi ...|\n",
            "|       4.9|     349.0|  4600.0|  6000|1 đôi tất hm cổ n...| null|              hà nội|   thời trang nam|                  no|                  no|      mô tả sản phẩm|         khosigiasoc|             1|       338700.0|                 0.79|  trong vài giờ|              48.0|         165900.0|1 đôi tất hm cổ n...| 1 đôi tất hm cổ n...|\n",
            "|       4.9|     144.0|   730.0| 32500|1 đôi tất không g...| null|          nước ngoài|thời trang trẻ em|thời trang trẻ em...|thời trang trẻ em...|            đặc điểm|          kidblue.vn|             0|       150500.0|                 0.95|  trong vài giờ|              32.0|         228300.0|1 đôi tất không g...| 1 đôi tất không g...|\n",
            "|       4.5|     589.0|  8100.0|  9000|1 đôi tất thể tha...| null|          nước ngoài|   thời trang nam|                  no|                  no|  thông tin chi tiết|       tangbaobao.vn|             0|        37100.0|                 0.42|  trong vài giờ|              15.0|          12400.0|1 đôi tất thể tha...| 1 đôi tất thể tha...|\n",
            "+----------+----------+--------+------+--------------------+-----+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+--------------+---------------+---------------------+---------------+------------------+-----------------+--------------------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "#Create PySpark SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BA Model\") \\\n",
        "    .getOrCreate()\n",
        "#Create PySpark DataFrame from Pandas\n",
        "# spark_df=spark.createDataFrame(df) \n",
        "spark_df = spark.read.format(\"csv\").option('header',\"true\").load('/content/drive/My Drive/ba_data_final.csv')\n",
        "# spark_df = spark.read.format(\"csv\").option('header',\"true\").load('data/ba_data_final.csv')\n",
        "\n",
        "spark_df.printSchema()\n",
        "spark_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "spqact-cEl4s"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "\n",
        "from pyspark.ml.feature import MinMaxScaler, StandardScaler\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "from pyspark.ml.feature import Imputer\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "from pyspark.ml.regression import LinearRegression, LinearRegressionSummary\n",
        "\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import log\n",
        "from math import log10\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "import numpy as np\n",
        "\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "\n",
        "def log_udf(s):\n",
        "  return log(s,10)\n",
        "\n",
        "class Model_Pipeline():\n",
        "  def __init__(self,\n",
        "               omit_fts = [],\n",
        "               model_save_path = \"checkpoint/model.model/\",\n",
        "               pipeline_save_path = 'checkpoint/pipeline.model/',\n",
        "               string_indexer_save_path = 'checkpoint/str_idx.model/',\n",
        "               model_name = 'random_forest', cross_validation = 0, text_process_method = 'tf-idf', min_doc_freq = 2, n_gram = 1,\n",
        "              text_attr ='name_description',\n",
        "              cat_attrs = [  'first_category', 'second_category', 'third_category', 'shop_like_tier'],\n",
        "              num_attrs = ['avg_rating', 'num_review' , 'num_sold', 'shop_num_review', 'shop_reply_percentage', 'shop_creation_time', 'shop_num_follower'],\n",
        "               omitted_fts = []):\n",
        "    \n",
        "    self.model_save_path = model_save_path\n",
        "    self.pipeline_save_path = pipeline_save_path\n",
        "    self.string_indexer_save_path = string_indexer_save_path\n",
        "    self.model_name = model_name\n",
        "    self.cross_validation = cross_validation\n",
        "    \n",
        "    self.text_process_method = text_process_method\n",
        "    self.min_doc_freq = min_doc_freq\n",
        "    self.n_gram = n_gram\n",
        "        \n",
        "    self.text_feature = text_attr\n",
        "    self.cat_features = cat_attrs\n",
        "    self.num_features = num_attrs\n",
        "\n",
        "    self.pipeline_list = []\n",
        "    self.pipeline = None\n",
        "\n",
        "    self.model = None\n",
        "\n",
        "    self.feature_columns = []\n",
        "    self.cv = cross_validation\n",
        "\n",
        "    self.omitted_fts = []\n",
        "\n",
        "    self.indexer =   StringIndexer(inputCols=[feature for feature in self.cat_features], outputCols= [ (feature + '_numeric' )for feature in self.cat_features])\n",
        "\n",
        "  \n",
        "  def build_pipeline(self):\n",
        "\n",
        "    # Process string attributes with TF-IDF or CountVectorizer \n",
        "    # for feature in self.text_features:\n",
        "    tokenizer = Tokenizer(inputCol=self.text_feature, outputCol=self.text_feature + \"_words\")\n",
        "    # wordsData = tokenizer.transform(self.df)\n",
        "    if self.text_feature not in self.omitted_fts:\n",
        "      if self.text_process_method == 'tf-idf':\n",
        "        hashing_tf = HashingTF(inputCol=self.text_feature + \"_words\", outputCol=self.text_feature + \"_rawFeatures\",numFeatures=500)\n",
        "        idf_transformer = IDF(inputCol=self.text_feature + \"_rawFeatures\", outputCol=self.text_feature + '_features',minDocFreq=self.min_doc_freq)\n",
        "        text_transformer = Pipeline(stages=[tokenizer,hashing_tf,idf_transformer])\n",
        "        self.pipeline_list.append(text_transformer)\n",
        "        self.feature_columns.append(self.text_feature + '_features')\n",
        "      \n",
        "      elif self.text_process_method == 'count-vectorizer':\n",
        "        cv = CountVectorizer(inputCol= self.text_feature + \"_words\", outputCol=self.text_feature + '_features')\n",
        "        text_transformer = Pipeline(stages=[tokenizer, cv])\n",
        "        self.pipeline_list.append(text_transformer)\n",
        "        self.feature_columns.append(self.text_feature + '_features')    \n",
        "\n",
        "    # # Process categorical variables: one hot encoding \n",
        "    # indexer = StringIndexer(inputCols=[feature for feature in self.cat_features], outputCols= [ (feature + '_numeric' )for feature in self.cat_features])\n",
        "    oh_encoder = OneHotEncoder(inputCols = [(feature + '_numeric')for feature in self.cat_features], outputCols = [ (feature + '_onehot' )for feature in self.cat_features])\n",
        "    categorical_transformer = Pipeline(stages=[oh_encoder])\n",
        "    self.pipeline_list.append(categorical_transformer)\n",
        "\n",
        "    for feature in self.cat_features:\n",
        "      if feature not in self.omitted_fts:\n",
        "        self.feature_columns.append(feature + '_onehot')\n",
        "\n",
        "    #Process numeric attributes\n",
        "    for feature in self.num_features:\n",
        "      if feature not in self.omitted_fts:\n",
        "        vectorAssembler = VectorAssembler(inputCols=[feature], outputCol=feature + '_unscaled')\n",
        "        scaler_for_feature = MinMaxScaler(inputCol=feature + '_unscaled', outputCol=feature + '_features')\n",
        "        numeric_transformer = Pipeline(stages = [vectorAssembler,scaler_for_feature])\n",
        "        self.pipeline_list.append(numeric_transformer)\n",
        "        self.feature_columns.append(feature + '_features')\n",
        "    \n",
        "\n",
        "    # Final feature assembler: assemble all chosen features\n",
        "    feature_assembler = VectorAssembler(inputCols=self.feature_columns, outputCol= 'features')\n",
        "    self.pipeline_list.append(feature_assembler)\n",
        "    self.pipeline = Pipeline(stages = self.pipeline_list)\n",
        "    \n",
        "\n",
        "    return self.pipeline\n",
        "  \n",
        "  def process_input_df(self,df):\n",
        "  \n",
        "    processed_df = df\n",
        "    processed_df = processed_df.fillna(0, subset=self.num_features)\n",
        "    for feature in self.num_features:\n",
        "      processed_df = processed_df.withColumn(feature, processed_df[feature].cast(DoubleType()))    \n",
        "    \n",
        "    processed_df = processed_df.withColumn('price', processed_df['price'].cast(DoubleType()))\n",
        "  \n",
        "    # processed_df = processed_df.withColumn(\"log_price\", F.log10(F.col('price')))    # processed_df = processed_df.withColumn(\"log_price\", log(df[\"price\"]) )\n",
        "    # processed_df.show()\n",
        "    processed_df = processed_df.withColumn(\"log_price\", F.log10(F.col('price')))    # processed_df = processed_df.withColumn(\"log_price\", log(df[\"price\"]) )\n",
        "\n",
        "    return processed_df\n",
        "  \n",
        "\n",
        "\n",
        "  def fit_transform(self, train_data):\n",
        "    df = self.process_input_df(train_data)\n",
        "    # print(df.summary())\n",
        "    # Process categorical variables: one hot encoding \n",
        "    # indexer = StringIndexer(inputCols=[feature for feature in self.cat_features], outputCols= [ (feature + '_numeric' )for feature in self.cat_features])\n",
        "    self.indexer = self.indexer.setHandleInvalid(\"skip\").fit(df)\n",
        "    df = self.indexer.transform(df)\n",
        "    # Build data processing pipeline\n",
        "    self.build_pipeline()\n",
        "    self.pipeline = self.pipeline.fit(df)\n",
        "    transformed_data = self.pipeline.transform(df)\n",
        "    transformed_data.select('features').show()\n",
        "    # model.transform(df).show()\n",
        "\n",
        "    # Create a model\n",
        "    if self.model_name == 'random_forest':\n",
        "      self.model = RandomForestRegressor(featuresCol=\"features\", labelCol=\"log_price\", predictionCol= 'log_prediction', numTrees=100)\n",
        "\n",
        "    if self.model_name == 'lr':\n",
        "      self.model =  LinearRegression(featuresCol=\"features\", labelCol=\"log_price\",predictionCol= 'log_prediction')\n",
        "    \n",
        "    elif self.model_name == 'gbt':\n",
        "      self.model = GBTRegressor(featuresCol=\"features\", labelCol='log_price', predictionCol='log_prediction')\n",
        "\n",
        "    self.model  = self.model.fit(transformed_data)\n",
        "    # result_df = self.model.transform(transformed_data).select(['price', 'log_prediction'])\n",
        "    # result_df = result_df.withColumn(\"prediction\", 10 ** F.col('log_prediction'))   \n",
        "    # self.model.transform(transformed_data).select(['price', 'log_prediction']).show()\n",
        "\n",
        "    if os.path.exists(self.model_save_path):\n",
        "      self.model.write().overwrite().save(self.model_save_path)\n",
        "    else:\n",
        "      self.model.save(self.model_save_path)\n",
        "\n",
        "    if os.path.exists(self.pipeline_save_path):\n",
        "      self.pipeline.write().overwrite().save(self.pipeline_save_path)\n",
        "    else:  \n",
        "      self.pipeline.save(self.pipeline_save_path)\n",
        "\n",
        "    if os.path.exists(self.string_indexer_save_path):\n",
        "      self.indexer.write().overwrite().save(self.string_indexer_save_path)\n",
        "    else:  \n",
        "      self.indexer.save(self.string_indexer_save_path)\n",
        "\n",
        "\n",
        "    # self.model.save(self.model_save_path)\n",
        "    # self.pipeline.save(self.pipeline_save_path)\n",
        "\n",
        "    return self.model\n",
        "  \n",
        "  def save(self,pipeline_path, model_path):\n",
        "    self.pipeline.save(pipeline_path)\n",
        "    self.model.save(model_path)\n",
        "\n",
        "  def predict(self, input_data, load = True):\n",
        "    if load:\n",
        "      self.model.load(self.model_save_path)\n",
        "      self.pipeline.load(self.pipeline_save_path)\n",
        "      self.indexer.load(self.string_indexer_save_path)\n",
        "    input_data = self.process_input_df(input_data)\n",
        "    input_data = self.indexer.transform(input_data)\n",
        "    transformed_data = self.pipeline.transform(input_data)\n",
        "\n",
        "    result_df = self.model.transform(transformed_data).select(['price', 'log_prediction'])\n",
        "    result_df = result_df.withColumn(\"prediction\", 10 ** F.col('log_prediction'))  \n",
        "    result_df.show() \n",
        "    \n",
        "    return result_df\n",
        "\n",
        "\n",
        "  \n",
        "  def hyper_tuning(self,train_data):\n",
        "    df = self.process_input_df(train_data)\n",
        "    # print(df.summary())\n",
        "    # Process categorical variables: one hot encoding \n",
        "    # indexer = StringIndexer(inputCols=[feature for feature in self.cat_features], outputCols= [ (feature + '_numeric' )for feature in self.cat_features])\n",
        "    self.indexer = self.indexer.setHandleInvalid(\"skip\").fit(df)\n",
        "    df = self.indexer.transform(df)\n",
        "    # Build data processing pipeline\n",
        "    self.build_pipeline()\n",
        "    self.pipeline = self.pipeline.fit(df)\n",
        "    transformed_data = self.pipeline.transform(df)\n",
        "    transformed_data.select('features').show()\n",
        "    # model.transform(df).show()\n",
        "\n",
        "    # Create a model\n",
        "    if self.model_name == 'random_forest':\n",
        "      self.model = RandomForestRegressor(featuresCol=\"features\", labelCol=\"log_price\", predictionCol= 'log_prediction')\n",
        "      # Create ParamGrid for Cross Validation\n",
        "      rfparamGrid = (ParamGridBuilder()\n",
        "            #  .addGrid(rf.maxDepth, [2, 5, 10, 20, 30])\n",
        "               .addGrid(self.model.maxDepth, [2, 5, 10])\n",
        "            #  .addGrid(.maxBins, [10, 20, 40, 80, 100])\n",
        "             #.addGrid(rf.numTrees, [5, 20, 50, 100, 500])\n",
        "               .addGrid(self.model.numTrees, [5, 20, 50])\n",
        "\n",
        "             .build())\n",
        "      rfevaluator = RegressionEvaluator(predictionCol=\"log_prediction\", labelCol=\"log_price\", metricName=\"r2\")\n",
        "      # Create 5-fold CrossValidator\n",
        "      rfcv = CrossValidator(estimator = self.model,\n",
        "                            estimatorParamMaps = rfparamGrid,\n",
        "                            evaluator = rfevaluator,\n",
        "                            numFolds = self.cv)\n",
        "      \n",
        "      self.model  = rfcv.fit(transformed_data)\n",
        "      if os.path.exists(self.model_save_path):\n",
        "        self.model.write().overwrite().save(self.model_save_path)\n",
        "      else:\n",
        "        self.model.save(self.model_save_path)\n",
        "\n",
        "      if os.path.exists(self.pipeline_save_path):\n",
        "        self.pipeline.write().overwrite().save(self.pipeline_save_path)\n",
        "      else:  \n",
        "        self.pipeline.save(self.pipeline_save_path)\n",
        "\n",
        "      if os.path.exists(self.string_indexer_save_path):\n",
        "        self.indexer.write().overwrite().save(self.string_indexer_save_path)\n",
        "      else:  \n",
        "        self.indexer.save(self.string_indexer_save_path)\n",
        "\n",
        "\n",
        "      # result_df = rfcv_model.transform(transformed_data).select(['price', 'log_prediction'])\n",
        "      # result_df = result_df.withColumn(\"prediction\", 10 ** F.col('log_prediction'))   \n",
        "      # rfcv_model.transform(transformed_data).select(['price', 'log_prediction']).show()\n",
        "\n",
        "      \n",
        "\n",
        "    if self.model_name == 'lr':\n",
        "      self.model =  LinearRegression(featuresCol=\"features\", labelCol=\"log_price\",predictionCol= 'log_prediction')\n",
        "      \n",
        "      lrevaluator = RegressionEvaluator(predictionCol=\"log_prediction\", labelCol=\"log_price\", metricName=\"r2\")\n",
        "      # Create 5-fold CrossValidator\n",
        "      lrparamGrid = ParamGridBuilder()\\\n",
        "                  .addGrid(self.model.regParam, [0.1, 0.01]) \\\n",
        "                  .addGrid(self.model.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
        "                  .build()\n",
        "\n",
        "      lrcv = CrossValidator(estimator = self.model,\n",
        "                            estimatorParamMaps = lrparamGrid,\n",
        "                            evaluator = lrevaluator,\n",
        "                            numFolds = self.cv)\n",
        "      \n",
        "      self.model  = lrcv.fit(transformed_data)\n",
        "\n",
        "    if self.model_name == 'gbt':\n",
        "      self.model = GBTRegressor(featuresCol=\"features\", labelCol='log_price', predictionCol='log_prediction')\n",
        "      \n",
        "      gbtevaluator = RegressionEvaluator(predictionCol=\"log_prediction\", labelCol=\"log_price\", metricName=\"r2\")\n",
        "      # Create 5-fold CrossValidator\n",
        "      gbtparamGrid = ParamGridBuilder()\\\n",
        "                  .addGrid(self.model.maxBins, [10, 20, 40]) \\\n",
        "                  .addGrid(self.model.maxDepth, [2, 5, 10])\\\n",
        "                  .build()\n",
        "\n",
        "      gbtcv = CrossValidator(estimator = self.model,\n",
        "                            estimatorParamMaps = gbtparamGrid,\n",
        "                            evaluator = gbtevaluator,\n",
        "                            numFolds = self.cv)\n",
        "      \n",
        "      self.model  = gbtcv.fit(transformed_data)\n",
        "\n",
        "    # elif self.model_name == 'gbt':\n",
        "    #   self.model = \n",
        "    return self.model\n",
        "\n",
        "  def evaluate(self, result_df):\n",
        "    rmse = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "    rmse = rmse.evaluate(result_df)\n",
        "    # mape = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mape\")\n",
        "    # mape = mape.evaluate(result_df)\n",
        "    r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "    r2 = r2.evaluate(result_df)\n",
        "  \n",
        "  # def feature_selection_experiment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "BpJ1hbNzEl4w"
      },
      "outputs": [],
      "source": [
        "full_df = spark_df\n",
        "train_df,  test_df = full_df.randomSplit([0.7,0.3], seed=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjCFev0IEl4x"
      },
      "source": [
        "# Experiment 1: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxtBmWKIEl4y",
        "outputId": "0f3e3ef9-bc84-4815-ee0c-0b9a9b24800b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|(735,[21,28,40,49...|\n",
            "|(735,[12,21,22,41...|\n",
            "|(735,[1,21,32,47,...|\n",
            "|(735,[7,8,19,21,2...|\n",
            "|(735,[0,4,6,19,32...|\n",
            "|(735,[13,45,49,89...|\n",
            "|(735,[0,4,7,28,38...|\n",
            "|(735,[104,106,201...|\n",
            "|(735,[40,64,105,1...|\n",
            "|(735,[17,18,25,27...|\n",
            "|(735,[0,15,19,32,...|\n",
            "|(735,[19,87,129,1...|\n",
            "|(735,[22,32,48,49...|\n",
            "|(735,[19,32,42,49...|\n",
            "|(735,[2,32,47,49,...|\n",
            "|(735,[4,13,32,41,...|\n",
            "|(735,[19,32,42,49...|\n",
            "|(735,[21,106,149,...|\n",
            "|(735,[0,32,49,86,...|\n",
            "|(735,[7,13,21,25,...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------+-----------------+------------------+\n",
            "|   price|   log_prediction|        prediction|\n",
            "+--------+-----------------+------------------+\n",
            "|100000.0|5.328461798522914|213040.31644543912|\n",
            "| 35000.0|5.026329884551503|106250.23139703862|\n",
            "|109000.0|5.052071998354094|112738.43410945764|\n",
            "| 99000.0|5.180230641874978|151436.52727363378|\n",
            "|653761.0|5.439827943116557| 275313.7761204475|\n",
            "| 99000.0|5.016153777569873|103789.58550911318|\n",
            "|399961.0|5.438619874798029| 274549.0054345606|\n",
            "|175000.0|5.077074072479916|119419.17662795319|\n",
            "| 69000.0|5.016464397077551|103863.84526415577|\n",
            "|117500.0|5.037412436447726|108996.47087868428|\n",
            "| 89000.0| 5.01176243755105|102745.41190127475|\n",
            "|302355.0|5.198012438780914|157765.64552653517|\n",
            "|329000.0|5.261353170357041|182537.95062948746|\n",
            "|145000.0|5.132453830433764| 135660.6302692646|\n",
            "|  4900.0| 4.92535076852764|  84207.4989457817|\n",
            "|109000.0|5.148531359266233|140776.88759930755|\n",
            "|183027.0|5.177688506734359|150552.68551426506|\n",
            "| 24000.0|4.581726573108475|38170.387873105195|\n",
            "|  1000.0|4.204411470387072|16010.742409489192|\n",
            "| 80000.0|4.624825717200198| 42152.73101608304|\n",
            "+--------+-----------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_save_path = 'checkpoint/rf_cv_model.model/'\n",
        "pipeline_save_path = 'checkpoint/rf_cv_pipeline.model/'\n",
        "indexer_save_path = 'checkpoint/rf_cv_indexer.model/'\n",
        "\n",
        "rf_pipeline = Model_Pipeline(text_process_method='tf-idf', model_name='random_forest', cross_validation=3,\n",
        "                             model_save_path=model_save_path,pipeline_save_path=pipeline_save_path,\n",
        "                             string_indexer_save_path=indexer_save_path)\n",
        "rf_pipeline.hyper_tuning(train_df)\n",
        "result_df = rf_pipeline.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOUtgA-kEl4y",
        "outputId": "aa0d3ae1-418d-4caa-a066-512a19afdbf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{Param(parent='RandomForestRegressor_a6f0dbaf56df', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10, Param(parent='RandomForestRegressor_a6f0dbaf56df', name='numTrees', doc='Number of trees to train (>= 1).'): 50}\n"
          ]
        }
      ],
      "source": [
        "print(rf_pipeline.model.getEstimatorParamMaps()[np.argmax(rf_pipeline.model.avgMetrics)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIEbfkVQEl4z",
        "outputId": "860d2a8c-ca16-4ee2-c433-9c89fe30baa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15493541826173066,\n",
              " 0.1605379324615471,\n",
              " 0.161269316021341,\n",
              " 0.29938608406887773,\n",
              " 0.3092304607009145,\n",
              " 0.3123334673339213,\n",
              " 0.4267070896663678,\n",
              " 0.45087903647696065,\n",
              " 0.4548645861234332]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "rf_pipeline.model.avgMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1DCwtWWEl40",
        "outputId": "c23e7856-f0c8-49c0-8a84-cd724ba8a475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------------+------------------+\n",
            "|   price|   log_prediction|        prediction|\n",
            "+--------+-----------------+------------------+\n",
            "|100000.0|5.328461798522914|213040.31644543912|\n",
            "| 35000.0|5.026329884551503|106250.23139703862|\n",
            "|109000.0|5.052071998354094|112738.43410945764|\n",
            "| 99000.0|5.180230641874978|151436.52727363378|\n",
            "|653761.0|5.439827943116557| 275313.7761204475|\n",
            "| 99000.0|5.016153777569873|103789.58550911318|\n",
            "|399961.0|5.438619874798029| 274549.0054345606|\n",
            "|175000.0|5.077074072479916|119419.17662795319|\n",
            "| 69000.0|5.016464397077551|103863.84526415577|\n",
            "|117500.0|5.037412436447726|108996.47087868428|\n",
            "| 89000.0| 5.01176243755105|102745.41190127475|\n",
            "|302355.0|5.198012438780914|157765.64552653517|\n",
            "|329000.0|5.261353170357041|182537.95062948746|\n",
            "|145000.0|5.132453830433764| 135660.6302692646|\n",
            "|  4900.0| 4.92535076852764|  84207.4989457817|\n",
            "|109000.0|5.148531359266233|140776.88759930755|\n",
            "|183027.0|5.177688506734359|150552.68551426506|\n",
            "| 24000.0|4.581726573108475|38170.387873105195|\n",
            "|  1000.0|4.204411470387072|16010.742409489192|\n",
            "| 80000.0|4.624825717200198| 42152.73101608304|\n",
            "+--------+-----------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result_df = rf_pipeline.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dbXe1fh-El41"
      },
      "outputs": [],
      "source": [
        "def rmsle(result_df,labelCol=\"price\", predictionCol=\"prediction\"):\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    \n",
        "    label = np.array(result_df.select(labelCol).collect())\n",
        "    prediction = np.array(result_df.select(predictionCol).collect())\n",
        "    \n",
        "    return np.sqrt(np.square(np.log(label + 1) - np.log(prediction + 1)).mean())\n",
        "rmsle = rmsle(result_df)\n",
        "r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "r2 = r2.evaluate(result_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2cPActeEl42",
        "outputId": "f1374a18-e8ec-461b-ad63-f0d7ec100bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7794082373546175 0.0871966678375441\n"
          ]
        }
      ],
      "source": [
        "print(rmsle, r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3szC2muxEl42"
      },
      "source": [
        "# Experiment 2: Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA3a8bHBEl42",
        "outputId": "41736b63-29e5-4bd7-a08c-9cc9461816b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|(735,[21,28,40,49...|\n",
            "|(735,[12,21,22,41...|\n",
            "|(735,[1,21,32,47,...|\n",
            "|(735,[7,8,19,21,2...|\n",
            "|(735,[0,4,6,19,32...|\n",
            "|(735,[13,45,49,89...|\n",
            "|(735,[0,4,7,28,38...|\n",
            "|(735,[104,106,201...|\n",
            "|(735,[40,64,105,1...|\n",
            "|(735,[17,18,25,27...|\n",
            "|(735,[0,15,19,32,...|\n",
            "|(735,[19,87,129,1...|\n",
            "|(735,[22,32,48,49...|\n",
            "|(735,[19,32,42,49...|\n",
            "|(735,[2,32,47,49,...|\n",
            "|(735,[4,13,32,41,...|\n",
            "|(735,[19,32,42,49...|\n",
            "|(735,[21,106,149,...|\n",
            "|(735,[0,32,49,86,...|\n",
            "|(735,[7,13,21,25,...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossValidatorModel_f24d1a536ee0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Linear regression\n",
        "model_save_path = 'checkpoint/lr_cv_model.model/'\n",
        "pipeline_save_path = 'checkpoint/lr_cv_pipeline.model/'\n",
        "indexer_save_path = 'checkpoint/lr_cv_indexer.model/'\n",
        "\n",
        "lr_pipeline = Model_Pipeline(text_process_method='tf-idf', model_name='lr', cross_validation=3\n",
        "                              ,model_save_path=model_save_path,pipeline_save_path=pipeline_save_path,\n",
        "                             string_indexer_save_path=indexer_save_path)\n",
        "lr_pipeline.hyper_tuning(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs0T6tJ6El43",
        "outputId": "c94f9a08-52d7-44a1-a224-63a18b0e7dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+------------------+\n",
            "|   price|    log_prediction|        prediction|\n",
            "+--------+------------------+------------------+\n",
            "|100000.0|4.6229830733384025|41974.262417039936|\n",
            "| 35000.0| 4.875467930392357| 75070.26179393864|\n",
            "|109000.0|5.1160592066421255|130634.89683681735|\n",
            "| 99000.0| 5.217941863342864| 165174.0673824245|\n",
            "|653761.0| 5.141184908500536|138415.55820716493|\n",
            "| 99000.0| 4.949022121224878| 88924.64113619637|\n",
            "|399961.0| 5.221261860181377|166441.59163590154|\n",
            "|175000.0| 5.186168189579721|153521.14102699482|\n",
            "| 69000.0| 4.853667365659403| 71394.92893735235|\n",
            "|117500.0| 5.024132873393433|105714.08944236723|\n",
            "| 89000.0| 5.170999529422518|148251.64787722187|\n",
            "|302355.0| 5.072150674342831|118073.02077226073|\n",
            "|329000.0| 5.134968543452487|136448.43015322147|\n",
            "|145000.0|5.1431788878213744|139052.52767903017|\n",
            "|  4900.0|  4.67608507981077|47433.490002776525|\n",
            "|109000.0| 5.097062370789736|125043.85978753652|\n",
            "|183027.0| 4.811688324613572| 64816.91021399408|\n",
            "| 24000.0|  4.40595604464367|25465.724985241493|\n",
            "|  1000.0| 4.583104634309914| 38291.69881651887|\n",
            "| 80000.0| 4.447660133239375| 28032.39042582113|\n",
            "+--------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_result_df = lr_pipeline.predict(test_df, load = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DIOM9y3El44",
        "outputId": "ad9c394a-fa30-41f3-cfc7-9bef96a18c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09690928592306225 0.7502347505839183\n"
          ]
        }
      ],
      "source": [
        "def rmsle(result_df,labelCol=\"price\", predictionCol=\"prediction\"):\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    \n",
        "    label = np.array(result_df.select(labelCol).collect())\n",
        "    prediction = np.array(result_df.select(predictionCol).collect())\n",
        "    \n",
        "    return np.sqrt(np.square(np.log(label + 1) - np.log(prediction + 1)).mean())\n",
        "rmsle = rmsle(lr_result_df)\n",
        "r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "r2 = r2.evaluate(lr_result_df)\n",
        "print(r2, rmsle)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Booosting Tree"
      ],
      "metadata": {
        "id": "3WDXBfj_VAP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "model_save_path = 'checkpoint/gbt_cv_model.model/'\n",
        "pipeline_save_path = 'checkpoint/gbt_cv_pipeline.model/'\n",
        "indexer_save_path = 'checkpoint/gbt_cv_indexer.model/'\n",
        "\n",
        "lr_pipeline = Model_Pipeline(text_process_method='tf-idf', model_name='gbt', cross_validation=3\n",
        "                              ,model_save_path=model_save_path,pipeline_save_path=pipeline_save_path,\n",
        "                             string_indexer_save_path=indexer_save_path)\n",
        "lr_pipeline.hyper_tuning(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PnhyaRDVC5H",
        "outputId": "3e9cb1e6-8dbd-4c72-a08a-003b2e2982f6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|(735,[21,28,40,49...|\n",
            "|(735,[12,21,22,41...|\n",
            "|(735,[1,21,32,47,...|\n",
            "|(735,[7,8,19,21,2...|\n",
            "|(735,[0,4,6,19,32...|\n",
            "|(735,[13,45,49,89...|\n",
            "|(735,[0,4,7,28,38...|\n",
            "|(735,[104,106,201...|\n",
            "|(735,[40,64,105,1...|\n",
            "|(735,[17,18,25,27...|\n",
            "|(735,[0,15,19,32,...|\n",
            "|(735,[19,87,129,1...|\n",
            "|(735,[22,32,48,49...|\n",
            "|(735,[19,32,42,49...|\n",
            "|(735,[2,32,47,49,...|\n",
            "|(735,[4,13,32,41,...|\n",
            "|(735,[19,32,42,49...|\n",
            "|(735,[21,106,149,...|\n",
            "|(735,[0,32,49,86,...|\n",
            "|(735,[7,13,21,25,...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossValidatorModel_9392df4b89b9"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbt_result = lr_pipeline.predict(test_df, load = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvvIuU0rY11M",
        "outputId": "96228508-4ba0-494e-e083-3300cd3f4e1f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+------------------+\n",
            "|   price|    log_prediction|        prediction|\n",
            "+--------+------------------+------------------+\n",
            "|100000.0|5.1763128824027715|150076.56552657625|\n",
            "| 35000.0| 5.064149888669369|115917.73556467587|\n",
            "|109000.0|4.9785920032907764| 95190.14827104405|\n",
            "| 99000.0| 5.780277610120832|  602944.877901053|\n",
            "|653761.0|5.6059296377386465|403580.00161861535|\n",
            "| 99000.0|4.9856413140016835| 96747.84808561488|\n",
            "|399961.0| 5.865742305383197| 734078.1635079588|\n",
            "|175000.0| 5.011640745434248|102716.62600691781|\n",
            "| 69000.0| 5.067729847935101|116877.21323436906|\n",
            "|117500.0|4.9979977318558575| 99540.02187658547|\n",
            "| 89000.0|4.9934755768461105| 98508.92433833734|\n",
            "|302355.0| 5.262416638520931| 182985.4837637902|\n",
            "|329000.0| 5.313996381086945|206061.27424107416|\n",
            "|145000.0|5.1144257938652125|130144.49239702361|\n",
            "|  4900.0| 4.193557626362892|15615.562265010314|\n",
            "|109000.0| 5.126353005494265|133768.23767033993|\n",
            "|183027.0| 4.983839441723878| 96347.27627666948|\n",
            "| 24000.0|4.3771211309392495| 23829.84024986714|\n",
            "|  1000.0|4.2948400308649255| 19716.96342691929|\n",
            "| 80000.0| 4.098807773932292| 12554.74146649761|\n",
            "+--------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsle(result_df,labelCol=\"price\", predictionCol=\"prediction\"):\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    \n",
        "    label = np.array(result_df.select(labelCol).collect())\n",
        "    prediction = np.array(result_df.select(predictionCol).collect())\n",
        "    \n",
        "    return np.sqrt(np.square(np.log(label + 1) - np.log(prediction + 1)).mean())\n",
        "rmsle = rmsle(gbt_result)\n",
        "r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "r2 = r2.evaluate(gbt_result)\n",
        "print(r2, rmsle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICKxWiBgZDp4",
        "outputId": "4e1a02ac-357e-44dd-f479-0e51ef578dd5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.5078826545942476 0.7624000046505081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ex 3:\n",
        "Text data "
      ],
      "metadata": {
        "id": "oaXK44F-Ipoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear regression\n",
        "model_save_path = 'checkpoint/lr_cv_model.model/'\n",
        "pipeline_save_path = 'checkpoint/lr_cv_pipeline.model/'\n",
        "indexer_save_path = 'checkpoint/lr_cv_indexer.model/'\n",
        "\n",
        "lr_augmented_text_pipeline = Model_Pipeline(text_process_method='tf-idf', model_name='lr', cross_validation=3,\n",
        "                                           text_attr ='augmented_description',\n",
        "       model_save_path=model_save_path,pipeline_save_path=pipeline_save_path,\n",
        "                             string_indexer_save_path=indexer_save_path)\n",
        "lr_augmented_text_pipeline.hyper_tuning(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt1v0InyIqth",
        "outputId": "3ef5da26-624c-4bf5-ebe5-0f9a57f9341c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|(735,[21,28,40,49...|\n",
            "|(735,[12,21,22,41...|\n",
            "|(735,[1,21,32,47,...|\n",
            "|(735,[7,8,19,21,2...|\n",
            "|(735,[0,4,6,19,32...|\n",
            "|(735,[13,45,49,89...|\n",
            "|(735,[0,4,7,28,38...|\n",
            "|(735,[49,104,106,...|\n",
            "|(735,[40,64,105,1...|\n",
            "|(735,[17,18,25,27...|\n",
            "|(735,[0,15,19,32,...|\n",
            "|(735,[19,87,129,1...|\n",
            "|(735,[22,32,48,49...|\n",
            "|(735,[19,32,42,49...|\n",
            "|(735,[2,32,47,49,...|\n",
            "|(735,[4,13,32,41,...|\n",
            "|(735,[19,32,42,49...|\n",
            "|(735,[21,49,106,1...|\n",
            "|(735,[0,32,49,86,...|\n",
            "|(735,[7,13,21,25,...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossValidatorModel_ea40668a19ab"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_text_result_df = lr_augmented_text_pipeline.predict(test_df, load = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjwC_OQOI1qr",
        "outputId": "c5e8e7d0-8fa7-4cba-e735-312bb73a7302"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+------------------+\n",
            "|   price|    log_prediction|        prediction|\n",
            "+--------+------------------+------------------+\n",
            "|100000.0| 4.621127320154411|41795.287804780295|\n",
            "| 35000.0|  4.86328304266858| 72993.30744260924|\n",
            "|109000.0| 5.098915194109758|125578.47191793415|\n",
            "| 99000.0|5.2343235178025616|171523.45567153592|\n",
            "|653761.0| 5.140403780512051| 138166.8258469042|\n",
            "| 99000.0| 4.945686691229401|  88244.3058567235|\n",
            "|399961.0| 5.222292204860905|166836.93582148192|\n",
            "|175000.0| 5.193098269198628| 155990.5427676853|\n",
            "| 69000.0| 4.875222151949121| 75027.78961669351|\n",
            "|117500.0| 5.034856163736559| 108356.7982032637|\n",
            "| 89000.0| 5.183584936993292|  152610.683343985|\n",
            "|302355.0| 5.085083935421073|121642.10737441931|\n",
            "|329000.0| 5.126298852696104|133751.55895792725|\n",
            "|145000.0| 5.146996723796223|140280.31221428525|\n",
            "|  4900.0| 4.684329069679172| 48342.49596809935|\n",
            "|109000.0| 5.093632952080223|124060.33572121356|\n",
            "|183027.0|4.8078255030296715| 64242.95410398304|\n",
            "| 24000.0| 4.398134595885598| 25011.20385020618|\n",
            "|  1000.0| 4.595434557566418| 39394.40610130662|\n",
            "| 80000.0| 4.427531441992259|26762.793430900543|\n",
            "+--------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsle(result_df,labelCol=\"price\", predictionCol=\"prediction\"):\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    \n",
        "    label = np.array(result_df.select(labelCol).collect())\n",
        "    prediction = np.array(result_df.select(predictionCol).collect())\n",
        "    \n",
        "    return np.sqrt(np.square(np.log(label + 1) - np.log(prediction + 1)).mean())\n",
        "rmsle = rmsle(lr_result_df)\n",
        "r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "r2 = r2.evaluate(augmented_text_result_df)\n",
        "print(r2, rmsle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw1gSZBAJhjW",
        "outputId": "0d72c330-d4e4-4910-efc4-d099ee34fcc9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10053909542602568 0.7502347505839183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count vectorizer experiment"
      ],
      "metadata": {
        "id": "TPs_2sdoSHnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get rid of numeric feautures with high correlation with the price\n",
        "omitted_fts = ['shop_like_tier', 'shop_review', 'shop_sold']\n",
        "# Linear regression\n",
        "model_save_path = 'checkpoint/lr_cv_model.model/'\n",
        "pipeline_save_path = 'checkpoint/lr_cv_pipeline.model/'\n",
        "indexer_save_path = 'checkpoint/lr_cv_indexer.model/'\n",
        "\n",
        "lr_count_vec_pipeline = Model_Pipeline(text_process_method='count-vectorizer', model_name='lr', cross_validation=3,\n",
        "                                           text_attr ='augmented_description',\n",
        "       model_save_path=model_save_path,pipeline_save_path=pipeline_save_path,\n",
        "                             string_indexer_save_path=indexer_save_path,\n",
        "                             omitted_fts = omitted_fts)\n",
        "lr_count_vec_pipeline.hyper_tuning(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyXM1qQKLAH-",
        "outputId": "39d3e0cf-097b-4e55-9917-363c77f68d90"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|            features|\n",
            "+--------------------+\n",
            "|(11489,[0,1,4,5,7...|\n",
            "|(11489,[0,6,10,14...|\n",
            "|(11489,[0,4,5,7,9...|\n",
            "|(11489,[0,2,3,4,5...|\n",
            "|(11489,[0,1,3,4,5...|\n",
            "|(11489,[0,1,2,4,5...|\n",
            "|(11489,[0,1,2,4,5...|\n",
            "|(11489,[0,1,2,11,...|\n",
            "|(11489,[0,2,17,22...|\n",
            "|(11489,[0,38,157,...|\n",
            "|(11489,[0,1,2,6,1...|\n",
            "|(11489,[0,4,5,7,9...|\n",
            "|(11489,[0,1,3,4,5...|\n",
            "|(11489,[0,1,3,4,5...|\n",
            "|(11489,[0,1,3,4,5...|\n",
            "|(11489,[0,3,4,5,7...|\n",
            "|(11489,[0,1,3,4,5...|\n",
            "|(11489,[0,1,2,10,...|\n",
            "|(11489,[0,1,6,11,...|\n",
            "|(11489,[0,2,4,5,6...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossValidatorModel_cf67bbfb9214"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vec_result = lr_count_vec_pipeline.predict(test_df, load = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY4-HXDgO_ZS",
        "outputId": "38cdc1d2-757e-4516-afe7-bcd191df9611"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+------------------+\n",
            "|   price|    log_prediction|        prediction|\n",
            "+--------+------------------+------------------+\n",
            "|100000.0| 4.771991358296545| 59154.98632468295|\n",
            "| 35000.0| 4.831829781040821|  67893.7475237261|\n",
            "|109000.0|5.0373326154885785| 108976.4397621591|\n",
            "| 99000.0| 5.221789881550247|  166644.076742473|\n",
            "|653761.0| 5.237655229935777|172844.36679667258|\n",
            "| 99000.0| 4.864929118493908|   73270.493809425|\n",
            "|399961.0| 5.279662289079756|190397.95921586052|\n",
            "|175000.0| 5.359288622980065| 228711.8269123763|\n",
            "| 69000.0| 4.859754941175453| 72402.72987760484|\n",
            "|117500.0| 4.920913243293499| 83351.46611819437|\n",
            "| 89000.0|  5.09405065303879|124179.71335871877|\n",
            "|302355.0| 5.001783157636082|100411.43128326368|\n",
            "|329000.0| 5.177687202258534|150552.23330487282|\n",
            "|145000.0| 5.118538161835456|131382.69370084992|\n",
            "|  4900.0| 4.389012723528192| 24491.34993117126|\n",
            "|109000.0|  5.04805140278893| 111699.5446751105|\n",
            "|183027.0|   4.8221813760605| 66402.03298437702|\n",
            "| 24000.0| 4.325543008711414| 21161.33238116174|\n",
            "|  1000.0|3.8912467802595994|7784.7878236407605|\n",
            "| 80000.0| 4.490780968229934|30958.575428312277|\n",
            "+--------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsle(result_df,labelCol=\"price\", predictionCol=\"prediction\"):\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    \n",
        "    label = np.array(result_df.select(labelCol).collect())\n",
        "    prediction = np.array(result_df.select(predictionCol).collect())\n",
        "    \n",
        "    return np.sqrt(np.square(np.log(label + 1) - np.log(prediction + 1)).mean())\n",
        "rmsle = rmsle(count_vec_result)\n",
        "r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "r2 = r2.evaluate(count_vec_result)\n",
        "print(r2, rmsle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQVI9D9ZRWZ2",
        "outputId": "49dc03d2-cdcf-4036-85d8-fbc7d6f0a3a1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.22148892396290387 0.7098799752478321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0o7nC-1TKk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dung",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6204c56dfdc43f3c45144e57abf0d5af5128d3580fd186720a131f94ef95cbe1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}